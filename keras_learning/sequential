
	#一、keras Sequential顺序模型结构
	#  第一步定义序列keras顺序模型
 	
	1. 		keras.models import Sequential 
	 		from keras.layers import Dense, Activation 
			 # 	使用构造函数的模式， 实例化一个序列模型， 一帮都不适用
			model = Sequential([
				Dense(32, input_shape=(784,)),
				Activation('relu'),
				Dense(10),
				Activation('softmax'),])
	2. 一般使用add将各个层添加到模型中
			model = Sequential()
			model.add(Dense(32, input_dim = 784))
			model.add(Activation('relu'))
			
	#  二、 指定输入数据的尺寸
	# 顺序模型的第一层（也仅仅是第一层）需要明确的指定输入数据的尺寸
	 1. 	model.Sequential()  #定义顺序模型
	 		model.add(Dense(32, input_shape=(784, )))  # 模型的第一层 这里是一个Dense层， 必须指定输入数据的尺寸
			# 这里的尺寸是batch_size = 32, input_shape=(784, None)  
			# 下面的代码和上面代码等价
			model = sequential()
			model.add(Dense(32, input_dim=784))
			
	# 三、 模型编译
	# 神经网络的结构构造完毕之后， 需要配置模型的参数， 这一步就是编译了
	# 模型编译需要就收三个参数, 分别是： optimizer 优化器， 损失函数loss,  评估标准metrics
	1. 	#针对多分类问题, 第一个参数是rmsprop梯度下降的优化算法， 第二个是交叉熵， 第三个是准确率， 分类人物的metrics一般都是accuarcy
		model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])
	2.	# 二分类问题
		model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])
	3.	# 回归问题， 回归问题的损失函数是均方误差， 评价标准就没了
		model.compile(optimizer='rmsprop', loss='mse')
	4.	# 自定义评估标准函数
		import keras.backend as K
		def mean_pred(y_true, y_pred):
			retrun K.mean(y_pred)
		model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy', mean_pred])
	
	# 四、 模型训练
	#  模型训练的时候就需要加入训练集和测试集数据了
	1.	# 对于具有两个类的当输入模型（二进制分类）
		model = Sequential()
		model.add(Dense(32, activation='relu', input_dim=100))
		model.add(Dense(1, activation='sigmoid'))  # 模型的第二层就不需要指定输入数据集的大小了
		model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])
		# 生成虚拟数据
		import numpy as np
		data = np.random.random((1000, 100))
		labels = np.random.random(2, size=(1000, 1))
		# 训练模型， 以32给样本问一个batch进行迭代
		model.fit(data, labels, epochs=10, batch_size=32)
	2. 	# 对于具有10个类的单输入模型（多分类）
		model = Sequential()
		model.add(Dense(32， activation='relu', input_dim=100))
		model.add(Dense(10, activation='softmax'))
		model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])
		#  生成虚拟数据
		impot numpy as np 
		data = np.random.random((1000, 100))
		labels = np.random.randint(10, size=(1000, 1))
		# 将标签数据转换成ont-hot编码（多分类问题都需要将label数据转换成one-hot编码）
		labels = keras.utils,to_categprical(labels, num_class= 10)
		model.fit(data, labels, epochs=10, batch_size=32)
	
	# 五、 样例
	
	1. #基于多层感知器（MLP）的softmax多分类
		import keras
		from keras.models import Sequential
		from keras.layers import Dense, Dropout, Activation
		from keras.optimizers import SGD
		
		# 生成虚拟数据
		import numpy as np 
		x_train = np.random.random((1000, 20))
		y_train = keras.utils.to_categorical(np.random.random((10, size=(1000, 1))), num_classes=10)
		x_test = np.random.random((100, 20))
		y_test = np.random.random(10, size=(100, 1))
		y_test = keras.utils.to_categorical(y_test, num_classes=10)
		
		# 搭建神经网络模型
		model = Sequential()
		# Dense(64)是一个具有64个隐藏神经元的全连接层
		# 在第一层必须指定所期望的输入数据尺寸
		# 在这里是一个20维向量
		model.add(Dense(64, activation='relu', input_dim=20))
		model.add(Dropout(0.5))
		model.add(Dense(64, activation='relu'))
		model.add(Dropout(0.5))
		model.add(Dense(10, activation='softmax'))
		sgd = SGD(lr=0.01, decy=1e-6, momentum=0.9, nesterov=True)
		model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])
		model.fit(x_train, y_train, epochs=20, batch_size=32)
		score = model.evaluate(x_test, y_test, batch_size=128)
	
	2.	# 基于多层感知器的二分类
		import numpy as np 
		from keras.modules import Sequential
		from keras.layers import Dense, Dropout
		
		# 生成虚拟数据
		x_train = np.random.random((1000, 20))
		y_train = np.random.randint(2, size=(1000, 1))
		x_test = np.random.random((100, 20))
		y_test = np.random.randint(2, size=(100, 1))
		
		# 创建模型
		model = Sequential()
		model.add(Dense(64, input_dim=20, activation='relu'))
		model.add(Dropout(0.5))
		model.add(Dense(64, activation='relu'))
		model.add(Dropout(0.5))
		model.add(Dense(1, activation='sigmoid'))
		
		# 编译模型
		model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])
		
		# 训练模型
		model.fit(x_train, y_train, epochs=20, batch_size=128)
		
		# 评价模型
		model.evaluate(x_test, y_test, batch_size=128)  
		
	3. 	# 类似与VGG的卷积神经网络
		
		# 头文件的导入
		importg numpy as np 
		import keras
		from keras.models import Sequential 
		from keras.layers import Dense, Dropout, Flatten
		from keras.layers import Conv2D, MaxPooling2D
		from keras.optimizers import SGD
		
		# 生成虚拟数据
		x_train = np.random.random((100, 100, 100, 3))
		y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1), num_classes=10))
		x_test = np.random.random((20, 100, 100, 3))
		y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1), num_classes=10))	
		
		# 创建模型
		model = Sequential()
		
		# 输入： 3 通道 100x100像素图像 -> （100， 100， 3）张量
		# 使用32个大小为3x3的卷积滤波器
		#  Conv2D的参数说明： 第一个是filter的个数, 第二个是filter的大小
		model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))
		model.add(Conv2D(32, (3, 3), activation='relu'))
		model.add(MaxPooling2D(pool_size=(2, 2)))
		model.add(Dropout(0.25))
		
		model.add(Conv2D(32, (3, 3), activation='relu'))
		model.add(Conv2D(32, (3, 3), activation='relu'))
		model.add(MaxPooling(pool_size=(2, 2)))
		model.add(Dropout(0.25))
		
		model.add(Flatten()) # 最后一层
		model.add(Dense(256, activation='relu'))
		model.add(Dropout(0.5))
		model.add(Dense(10, activation='softmax'))
		
		sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
		model.compile(loss='categorical_crossentropy', optimizer=sgd )
		
		model.fit(x_train, y_train, batch_size=32, epochs=10)
		score = model.evaluate(x_test, y_test, batch_size=32)

	
	4. 	# 基于1D卷积的序列分类
		from keras.models import Sequential
		from keras.layers import Dense, Dropout
		from keras.layers import Embeddiing 
		from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D
		
		seq_length = 64
		
		model = Sequential()
		
		#  注意1D的卷积层和池化层与2D的区别 这个卷积核只有一维啊
		model.add(Conv1D(64, 3, activation='relu', input_shape=(seq_length, 100)))
		model.add(Conv1D(64, 3, activation='relu'))
		model.add(MaxPooling1D(3))
		model.add(Conv1D(128, 3, activation='relu'))
		model.add(Conv1D(128, 3, activation='relu'))
		model.add(GlobalAveragePooling1D())
		model.add(Dropout(0.5))
		model.add(Dense(1, activation='sigmoid'))
		
		model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
		model.fit(x_train, y_train, batch_size=16, epochs=10)
		score = mode.evaluate(x_test, y_test, batch_size=16)
		
	5. 	# 基于栈式LSTM的序列分类
		from keras.models import Sequential 
		from keras.layers import LSTM, Dense
		import numpy as np
		
		data_dim = 16
		timesteps = 8
		num_classes = 10
		
		# 期望输入数据的尺寸
		model = Sequential()
		model.add(LSTM(32, return_sequences=True, input_shape=(timesteps, data_dim)))
				
		model.add(LSTM(32, return_sequences=True))  # 返回维度为 32 的向量序列
		model.add(LSTM(32))  # 返回维度为 32 的单个向量
		model.add(Dense(10, activation='softmax'))

		model.compile(loss='categorical_crossentropy',
			      optimizer='rmsprop',
			      metrics=['accuracy'])

		# 生成虚拟训练数据
		x_train = np.random.random((1000, timesteps, data_dim))
		y_train = np.random.random((1000, num_classes))

		# 生成虚拟验证数据
		x_val = np.random.random((100, timesteps, data_dim))
		y_val = np.random.random((100, num_classes))

		model.fit(x_train, y_train,
			  batch_size=64, epochs=5,
			  validation_data=(x_val, y_val))








		
		
		
		
		
		
		
		
